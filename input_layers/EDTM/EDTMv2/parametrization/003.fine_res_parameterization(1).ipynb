{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b959b3d0-a0d4-4da7-9f27-f915530d0871",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Land relief parameterization in coarser resolution \n",
    "\n",
    "This script is used to generate the fine resolution land relief parameters. The data would be cropped into tiles in 6 continents, Africa, Asia, Europe, South America, and North America. Each tile would be extended to have overlap to prevent border effect. The tiles has been generated by `002.generate_tiles.ipynb`, and stored in `equi7_tiles`. \n",
    "\n",
    "Each tile runs in its individual process with a stream of parameterization. A landmask is used to mask out the ocean pixels. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06431dbb-e8bd-4a8e-816c-0795d2d99289",
   "metadata": {},
   "source": [
    "## Part 1: Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fed3be49-cd90-45c7-bf38-3837b3a101d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from shapely.geometry import Polygon,mapping,box\n",
    "from shapely import segmentize\n",
    "import time\n",
    "import sys\n",
    "from joblib import Parallel, delayed\n",
    "from minio import Minio\n",
    "from eumap.misc import ttprint\n",
    "import requests\n",
    "import pandas as pd\n",
    "import pickle\n",
    "# set up whiteboxworkflow environment\n",
    "import whitebox_workflows\n",
    "from whitebox_workflows import download_sample_data, show, WbEnvironment\n",
    "wbe = whitebox_workflows.WbEnvironment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a833526b-cccb-491a-b9d4-862cdf321b3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parameters</th>\n",
       "      <th>old_data_type</th>\n",
       "      <th>ori_min</th>\n",
       "      <th>ori_max</th>\n",
       "      <th>multiplier</th>\n",
       "      <th>new_data_type</th>\n",
       "      <th>final_min</th>\n",
       "      <th>final_max</th>\n",
       "      <th>no_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>geomorphon</td>\n",
       "      <td>Int16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>Byte</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hillshade</td>\n",
       "      <td>Float32</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28357.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>UInt16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28357.000000</td>\n",
       "      <td>65535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>slope.in.degree</td>\n",
       "      <td>Float32</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.29000</td>\n",
       "      <td>100</td>\n",
       "      <td>UInt16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1529.000000</td>\n",
       "      <td>65535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ls.factor</td>\n",
       "      <td>Float32</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.00000</td>\n",
       "      <td>1000</td>\n",
       "      <td>UInt16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13000.000000</td>\n",
       "      <td>65535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pro.curv</td>\n",
       "      <td>Float32</td>\n",
       "      <td>-8.210329</td>\n",
       "      <td>8.01173</td>\n",
       "      <td>1000</td>\n",
       "      <td>Int16</td>\n",
       "      <td>-8210.329056</td>\n",
       "      <td>8011.730194</td>\n",
       "      <td>32767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        parameters old_data_type   ori_min     ori_max   multiplier  \\\n",
       "0       geomorphon         Int16  1.000000     10.00000           1   \n",
       "1        hillshade       Float32  0.000000  28357.00000           1   \n",
       "2  slope.in.degree       Float32  0.000000     15.29000         100   \n",
       "3        ls.factor       Float32  0.000000     13.00000        1000   \n",
       "4         pro.curv       Float32 -8.210329      8.01173        1000   \n",
       "\n",
       "  new_data_type    final_min    final_max   no_data  \n",
       "0          Byte     1.000000     10.000000      255  \n",
       "1        UInt16     0.000000  28357.000000    65535  \n",
       "2        UInt16     0.000000   1529.000000    65535  \n",
       "3        UInt16     0.000000  13000.000000    65535  \n",
       "4         Int16 -8210.329056   8011.730194    32767  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## scale factors for each parameters\n",
    "p_table=pd.read_csv('scaling.csv')\n",
    "p_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e60dbb6d-7967-4119-8006-04ec27db0e68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#os.system(f'rm -r tmp-global-geomorpho/*')\n",
    "with open('shuf.txt', 'r') as file:\n",
    "    shuf = [int(line.strip()) for line in file]\n",
    "    \n",
    "with open(f'equi7_tiles', \"rb\") as fp:   # Unpickling\n",
    "    args_whole = pickle.load(fp)\n",
    "    \n",
    "start_tile=0\n",
    "end_tile=790\n",
    "args = args_whole[start_tile:end_tile]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4c601fe-f715-439b-b2bf-427b851492f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "790"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acaf9554-c391-4a43-ac29-64a26f14886f",
   "metadata": {},
   "source": [
    "## Part 2: parametrization by tiles\n",
    "\n",
    "The parametrization using pyramid representation. The steps include:\n",
    "\n",
    "1. create local tile and convert DTM value from decimeter to meter and save it as float\n",
    "2. crop the landmask to the given tile.\n",
    "3. apply guassian filter at 30m \n",
    "4. apply paramtrization \n",
    "5. crop and save the parameters raster into local tile\n",
    "6. push to back the S3 server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808b8507-f983-4214-96e6-cc1bf29f3ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for info in args:\n",
    "    equi7_bounds_final,equi7_bounds_rls,epsg4326_bounds_rls,equi7_bounds_ls,epsg4326_bounds_ls,tile_name,equi_7_proj = info[0],info[1],info[2],info[3],info[4],info[5],info[6]\n",
    "\n",
    "\n",
    "    outdir=f'tmp-global-geomorpho/{tile_name}'\n",
    "    os.makedirs(outdir,exist_ok=True)\n",
    "    gdalwarp_bbox_rls = ' '.join([str(i) for i in equi7_bounds_rls])\n",
    "    gdalwarp_bbox_ls = ' '.join([str(i) for i in equi7_bounds_ls])\n",
    "    gdalwarp_bbox_final = ' '.join([str(i) for i in equi7_bounds_final])\n",
    "    filepath = 'legendtm_rf_30m_m_s_20000101_20231231_go_epsg.4326_v20250130.tif'\n",
    "\n",
    "    start_time = time.time()\n",
    "    tmp_outdir=f'/tmp/tmp-global-geomorpho/{tile_name}'\n",
    "    os.makedirs(tmp_outdir,exist_ok=True)\n",
    "    gdal_cmd = f'gdalwarp  -co TILED=YES -co BIGTIFF=YES -co COMPRESS=DEFLATE \\\n",
    "    -co ZLEVEL=9 -co BLOCKXSIZE=1024 -co BLOCKYSIZE=1024 -co NUM_THREADS=8 \\\n",
    "    -co SPARSE_OK=TRUE -of GTiff -overwrite'\n",
    "    out_ori_file=f'dtm_edtm_m_30m_s_20000101_20221231_{tile_name.lower().replace(\"_\",\".\")}.rls_equi7_v20241230.tif'\n",
    "    url_rls=f'{ip}://tmp-global-geomorpho/{tile_name}/{out_ori_file}'\n",
    "\n",
    "    r = requests.head(url_rls)\n",
    "    if r.status_code == 200:\n",
    "        ttprint(f'{url_rls} exists')\n",
    "    else:\n",
    "        rn_file = f'{tmp_outdir}/{out_ori_file}'\n",
    "        os.system(f'{gdal_cmd} -t_srs \"{equi_7_proj}\" \\\n",
    "        -te {gdalwarp_bbox_rls} -tr 30 30 -r bilinear {filepath} {tmp_outdir}/scaled_dtm_tmp_rls.tif')\n",
    "        os.system(f'gdal_calc.py --overwrite -A {tmp_outdir}/scaled_dtm_tmp_rls.tif \\\n",
    "        --outfile={rn_file} --calc=\"A * 0.1\" \\\n",
    "        --type=Float32 --co=\"COMPRESS=DEFLATE\" --co=\"BLOCKXSIZE=2048\" --co=\"BLOCKYSIZE=2048\"')\n",
    "        \n",
    "    for resolution in [30,60,120,240]:\n",
    "        url=f'{ip}://tmp-global-geomorpho/{tile_name}/tan.curv_edtm_m_{resolution}m_s_20000101_20221231_go_epsg.4326_v20241230.tif'\n",
    "        r = requests.head(url)\n",
    "        if r.status_code == 200:\n",
    "            ttprint(f'{tile_name} has been process')\n",
    "            return\n",
    "\n",
    "        if resolution==30:\n",
    "            tmp_dtm_rls_file = f'{tmp_outdir}/dtm_tmp_rls_{resolution}.tif'\n",
    "            os.system(f'{gdal_cmd} /vsicurl/{url_rls} {tmp_dtm_rls_file}')\n",
    "            # crop to local land surface tiff\n",
    "            tmp_dtm_ls_file = f'{tmp_outdir}/dtm_tmp_ls.tif'\n",
    "            os.system(f'{gdal_cmd} -te {gdalwarp_bbox_ls} /vsicurl/{url_rls} {tmp_dtm_ls_file}')\n",
    "\n",
    "        else:            \n",
    "            # crop to regional land surface tiff\n",
    "            tmp_dtm_rls_file = f'{tmp_outdir}/dtm_tmp_rls_{resolution}.tif'\n",
    "            os.system(f'{gdal_cmd} -r average -tr {resolution} {resolution} -te {gdalwarp_bbox_rls} /vsicurl/{url_rls} {tmp_dtm_rls_file}')\n",
    "     \n",
    "            # crop to local land surface tiff\n",
    "            tmp_dtm_ls_file = f'{tmp_outdir}/dtm_tmp_ls_{resolution}.tif'\n",
    "            os.system(f'{gdal_cmd} -r average -tr {resolution} {resolution} -te {gdalwarp_bbox_ls} /vsicurl/{url_rls} {tmp_dtm_ls_file}')\n",
    "    \n",
    "        # crop the landmask\n",
    "        global_landmask_file='{ip}://global/dsm.landmask_ensemble_m_30m_s_20000101_20221231_go_epsg.4326_v4.1.tif'\n",
    "        tmp_landmask_file = f'{tmp_outdir}/landmask_{resolution}.tif'\n",
    "        os.system(f'{gdal_cmd} -t_srs \"{equi_7_proj}\" -r min -tr {resolution} {resolution} -te {gdalwarp_bbox_final} {global_landmask_file} {tmp_landmask_file}')\n",
    "\n",
    "\n",
    "        start_time = time.time()\n",
    "        # Reading raster data\n",
    "        dtm = wbe.read_raster(tmp_dtm_rls_file)\n",
    "        ttprint(f\"{tile_name} read_raster--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "        file_list=[]\n",
    "        if resolution == 30:\n",
    "            start_time = time.time()\n",
    "            dtm = wbe.gaussian_filter(dtm)\n",
    "            ttprint(f\"{tile_name} calculate gaussian filter--- %s seconds ---\" % (time.time() - start_time))    \n",
    "\n",
    "\n",
    "        # geomorphon\n",
    "        #tmp_geomorphon_file=tmp_dtm_rls_file.replace('dtm','geomorphon')\n",
    "        #scale=p_table[p_table['parameters']=='geomorphon'].multiplier.iloc[0]\n",
    "\n",
    "        #start_time = time.time()\n",
    "        #geomorphon=wbe.geomorphons(dtm, search_distance=3, \n",
    "        #                          output_forms=True, analyze_residuals=False)\n",
    "        #wbe.write_raster(geomorphon*scale, tmp_geomorphon_file, compress=True)#, compress=False) # Compression is good, but it is a bit slower so here we won't use it.\n",
    "        #ttprint(f\"{tile_name} calculate geomporphon--- %s seconds ---\" % (time.time() - start_time))    \n",
    "        #file_list.append(tmp_geomorphon_file)\n",
    "\n",
    "\n",
    "        # fill depression for hydrological analysis\n",
    "        tmp_flled_dtm_file=tmp_dtm_rls_file.replace('dtm','nodepress.dtm')\n",
    "        scale=p_table[p_table['parameters']=='nodepress.dtm'].multiplier.iloc[0]\n",
    "\n",
    "        start_time = time.time()\n",
    "        dtm_no_deps = wbe.breach_depressions_least_cost(dtm, fill_deps=True, flat_increment=0.001)\n",
    "        wbe.write_raster(dtm_no_deps*scale, tmp_flled_dtm_file, compress=True)#, compress=False) # Compression is good, but it is a bit slower so here we won't use it.\n",
    "        ttprint(f\"{tile_name} fill depressions--- %s seconds ---\" % (time.time() - start_time))    \n",
    "        file_list.append(tmp_flled_dtm_file)\n",
    "\n",
    "\n",
    "        # slope for hydrology\n",
    "        tmp_slope_file=tmp_dtm_rls_file.replace('dtm','slope.in.degree')\n",
    "        scale=p_table[p_table['parameters']=='slope.in.degree'].multiplier.iloc[0]\n",
    "\n",
    "        start_time = time.time()\n",
    "        slope_in_degree = wbe.slope(dtm)\n",
    "        wbe.write_raster(slope_in_degree*scale, tmp_slope_file, compress=True)#, compress=False) # Compression is good, but it is a bit slower so here we won't use it.\n",
    "        ttprint(f\"{tile_name} calculate slope--- %s seconds ---\" % (time.time() - start_time))\n",
    "        file_list.append(tmp_slope_file)\n",
    "\n",
    "        # SCA\n",
    "        tmp_sca_file=tmp_dtm_rls_file.replace('dtm','spec.catch')\n",
    "        scale=p_table[p_table['parameters']=='spec.catch'].multiplier.iloc[0]\n",
    "\n",
    "        start_time = time.time()\n",
    "        sca = wbe.qin_flow_accumulation(dtm_no_deps, out_type='sca', log_transform=True)\n",
    "        wbe.write_raster(sca*scale, tmp_sca_file, compress=True)#, compress=False) # Compression is good, but it is a bit slower so here we won't use it.\n",
    "        ttprint(f\"{tile_name} specific catchment area--- %s seconds ---\" % (time.time() - start_time))\n",
    "        file_list.append(tmp_sca_file)\n",
    "\n",
    "        # ls factor\n",
    "        tmp_lsfactor_file=tmp_dtm_rls_file.replace('dtm','ls.factor')\n",
    "        start_time = time.time()\n",
    "        scale=p_table[p_table['parameters']=='ls.factor'].multiplier.iloc[0]\n",
    "\n",
    "        ls_factor=wbe.sediment_transport_index(sca, slope_in_degree, sca_exponent=0.4, slope_exponent=1.3)\n",
    "        wbe.write_raster(ls_factor*scale, tmp_lsfactor_file, compress=True)#, compress=False) # Compression is good, but it is a bit slower so here we won't use it.\n",
    "        ttprint(f\"{tile_name} calculate ls factor--- %s seconds ---\" % (time.time() - start_time))    \n",
    "        file_list.append(tmp_lsfactor_file)\n",
    "\n",
    "        #twi\n",
    "        start_time = time.time()\n",
    "        tmp_twi_file=tmp_dtm_rls_file.replace('dtm','twi')\n",
    "        scale=p_table[p_table['parameters']=='twi'].multiplier.iloc[0]\n",
    "\n",
    "        twi = wbe.wetness_index(specific_catchment_area=sca, slope=slope_in_degree)\n",
    "        #twi_filled = wbe.fill_missing_data(twi, exclude_edge_nodata=True)\n",
    "        ttprint(f\"{tile_name} topographic wetness index--- %s seconds ---\" % (time.time() - start_time))\n",
    "        wbe.write_raster(twi*scale, tmp_twi_file, compress=True) # Compression is good, but it is a bit slower so here we won't use it.\n",
    "        file_list.append(tmp_twi_file)\n",
    "\n",
    "        # Reading raster data\n",
    "        start_time = time.time()\n",
    "        # Reading raster data\n",
    "        dtm = wbe.read_raster(tmp_dtm_ls_file)\n",
    "        ttprint(f\"{tile_name} read local surface raster--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "        # diff from mean elev\n",
    "        start_time = time.time()\n",
    "        tmp_dfme_file=tmp_dtm_ls_file.replace('dtm','dfme')\n",
    "        scale=p_table[p_table['parameters']=='dfme'].multiplier.iloc[0]\n",
    "\n",
    "        dfme=wbe.difference_from_mean_elevation(\n",
    "            dtm, \n",
    "            filter_size_x=3, \n",
    "            filter_size_y=3)\n",
    "\n",
    "        wbe.write_raster(dfme*scale, tmp_dfme_file, compress=True) # Compression is good, but it is a bit slower so here we won't use it.\n",
    "        ttprint(f\"{tile_name} diff from mean elev--- %s seconds ---\" % (time.time() - start_time))\n",
    "        file_list.append(tmp_dfme_file)\n",
    "\n",
    "        #Spherical Std Dev Of Normals\n",
    "        start_time = time.time()\n",
    "        tmp_ssdon_file=tmp_dtm_ls_file.replace('dtm','ssdon')\n",
    "        scale=p_table[p_table['parameters']=='ssdon'].multiplier.iloc[0]\n",
    "\n",
    "        start_time = time.time()\n",
    "        ssdon=wbe.spherical_std_dev_of_normals(\n",
    "            dtm, \n",
    "            filter_size=3 \n",
    "        )\n",
    "\n",
    "        wbe.write_raster(ssdon*scale, tmp_ssdon_file, compress=True) # Compression is good, but it is a bit slower so here we won't use it.\n",
    "        ttprint(f\"{tile_name} spherical std dev of normals--- %s seconds ---\" % (time.time() - start_time))\n",
    "        file_list.append(tmp_ssdon_file)\n",
    "\n",
    "        if resolution == 30:\n",
    "            start_time = time.time()\n",
    "            dtm_g = wbe.gaussian_filter(dtm)\n",
    "            ttprint(f\"{tile_name} calculate gaussian filter--- %s seconds ---\" % (time.time() - start_time))\n",
    "            tmp_dtm_gaus_file=tmp_dtm_rls_file.replace('dtm','filtered.dtm')\n",
    "            scale=p_table[p_table['parameters']=='filtered.dtm'].multiplier.iloc[0]\n",
    "            wbe.write_raster(dtm_g*scale, tmp_dtm_gaus_file, compress=True)#, compress=False) # Compression is good, but it \n",
    "            del dtm\n",
    "            dtm = wbe.read_raster(tmp_dtm_gaus_file)\n",
    "            file_list.append(tmp_dtm_gaus_file)\n",
    "\n",
    "        # Hillshade\n",
    "        tmp_hillshade_file=tmp_dtm_ls_file.replace('dtm','hillshade')\n",
    "        scale=p_table[p_table['parameters']=='hillshade'].multiplier.iloc[0]\n",
    "\n",
    "        start_time = time.time()\n",
    "        hs = wbe.multidirectional_hillshade(dtm)\n",
    "        wbe.write_raster(hs*scale, tmp_hillshade_file, compress=True)#, compress=False) # Compression is good, but it is a bit slower so here we won't use it.\n",
    "        ttprint(f\"{tile_name} calculate hillshade--- %s seconds ---\" % (time.time() - start_time))    \n",
    "        file_list.append(tmp_hillshade_file)\n",
    "\n",
    "        # Minic\n",
    "        tmp_minic_file=tmp_dtm_ls_file.replace('dtm','minic')\n",
    "        scale=p_table[p_table['parameters']=='minic'].multiplier.iloc[0]\n",
    "\n",
    "        start_time = time.time()\n",
    "        minic = wbe.minimal_curvature(dtm, log_transform=True)\n",
    "        wbe.write_raster(minic*scale, tmp_minic_file, compress=True)#, compress=False) # Compression is good, but it is a bit slower so here we won't use it.\n",
    "        ttprint(f\"{tile_name} calculate minic--- %s seconds ---\" % (time.time() - start_time))\n",
    "        file_list.append(tmp_minic_file)\n",
    "\n",
    "\n",
    "        # Maxic\n",
    "        tmp_maxic_file=tmp_dtm_ls_file.replace('dtm','maxic')\n",
    "        scale=p_table[p_table['parameters']=='maxic'].multiplier.iloc[0]\n",
    "\n",
    "        start_time = time.time()\n",
    "        maxic = wbe.maximal_curvature(dtm, log_transform=True)\n",
    "        wbe.write_raster(maxic*scale, tmp_maxic_file, compress=True)#, compress=False) # Compression is good, but it is a bit slower so here we won't use it.\n",
    "        ttprint(f\"{tile_name} calculate maxic--- %s seconds ---\" % (time.time() - start_time))    \n",
    "        file_list.append(tmp_maxic_file)\n",
    "\n",
    "        # Openness\n",
    "        tmp_pos_file=tmp_dtm_ls_file.replace('dtm','pos.openness')\n",
    "        tmp_neg_file=tmp_dtm_ls_file.replace('dtm','neg.openness')\n",
    "        start_time = time.time()\n",
    "        pos,neg = wbe.openness(dtm,dist=3)\n",
    "        scale=p_table[p_table['parameters']=='pos.openness'].multiplier.iloc[0]\n",
    "        wbe.write_raster(pos*scale, tmp_pos_file, compress=True)#, compress=False) # Compression is good, but it is a bit slower so here we won't use it.\n",
    "        scale=p_table[p_table['parameters']=='neg.openness'].multiplier.iloc[0]\n",
    "\n",
    "        wbe.write_raster(neg*scale, tmp_neg_file, compress=True)#, compress=False) # Compression is good, but it is a bit slower so here we won't use it.\n",
    "\n",
    "        ttprint(f\"{tile_name} calculate openness--- %s seconds ---\" % (time.time() - start_time))    \n",
    "        file_list.append(tmp_pos_file)\n",
    "        file_list.append(tmp_neg_file)\n",
    "\n",
    "\n",
    "        # profile curve\n",
    "        start_time = time.time()\n",
    "        tmp_procurv_file=tmp_dtm_ls_file.replace('dtm','pro.curv')\n",
    "        scale=p_table[p_table['parameters']=='pro.curv'].multiplier.iloc[0]\n",
    "        procurv = wbe.profile_curvature(dtm, log_transform=True)\n",
    "        wbe.write_raster(procurv*scale, tmp_procurv_file, compress=True) # Compression is good, but it is a bit slower so here we won't use it.\n",
    "        ttprint(f\"{tile_name} profile curve --- %s seconds ---\" % (time.time() - start_time))\n",
    "        file_list.append(tmp_procurv_file)\n",
    "\n",
    "\n",
    "        # shape index\n",
    "        start_time = time.time()\n",
    "        tmp_shpindx_file=tmp_dtm_ls_file.replace('dtm','shpindx')\n",
    "        scale=p_table[p_table['parameters']=='shpindx'].multiplier.iloc[0]\n",
    "        shpindx=wbe.shape_index(dtm)\n",
    "        wbe.write_raster(shpindx*scale, tmp_shpindx_file, compress=True)\n",
    "        ttprint(f\"{tile_name} shape index --- %s seconds ---\" % (time.time() - start_time))\n",
    "        file_list.append(tmp_shpindx_file)\n",
    "\n",
    "        # ring curvature\n",
    "        start_time = time.time()\n",
    "        tmp_ring_curv_file=tmp_dtm_ls_file.replace('dtm','ring.curv')\n",
    "        scale=p_table[p_table['parameters']=='ring.curv'].multiplier.iloc[0]\n",
    "        ring_curv=wbe.ring_curvature(dtm, log_transform=True)\n",
    "\n",
    "        ttprint(f\"{tile_name} ring curvature --- %s seconds ---\" % (time.time() - start_time))\n",
    "        file_list.append(tmp_ring_curv_file)\n",
    "\n",
    "        # tangential curvatures\n",
    "        start_time = time.time()\n",
    "        tmp_tan_curv_file=tmp_dtm_ls_file.replace('dtm','tan.curv')\n",
    "        scale=p_table[p_table['parameters']=='tan.curv'].multiplier.iloc[0]\n",
    "\n",
    "        tan_curv=wbe.tangential_curvature(dtm, log_transform=True)\n",
    "        wbe.write_raster(tan_curv*scale, tmp_tan_curv_file, compress=True) # Compression is good, but it is a bit slower so here we won't use it.\n",
    "        ttprint(f\"{tile_name} tangential curvature --- %s seconds ---\" % (time.time() - start_time))\n",
    "        file_list.append(tmp_tan_curv_file)\n",
    "\n",
    "\n",
    "        start_time = time.time()\n",
    "        def para_gdal_warp(file_path,tile_name,bbox,p_table,tmp_landmask_file):\n",
    "            file_name = file_path.split('/')[-1]\n",
    "            parameter = file_name.split('_')[0]\n",
    "            dtype=p_table[p_table['parameters']==parameter].new_data_type.iloc[0]\n",
    "            no_data=p_table[p_table['parameters']==parameter].no_data.iloc[0]\n",
    "\n",
    "            gdalcmd = f'gdalwarp -overwrite -ot {dtype} -tr {resolution} {resolution} -te {bbox} -co TILED=YES -co BIGTIFF=YES -co COMPRESS=DEFLATE -co ZLEVEL=9 -co BLOCKXSIZE=2048 -co BLOCKYSIZE=2048 -co NUM_THREADS=8 -co SPARSE_OK=TRUE'\n",
    "\n",
    "            file_name = parameter + '_edtm' + '_m' + f'_{resolution}m' + '_s' + '_20000101_20221231' + '_go'  + '_epsg.4326' + '_v20241230' + '.tif'\n",
    "            out_path = f'{outdir}/{file_name}'\n",
    "            tmp_out_path = f'{outdir}/tmp_{file_name}'\n",
    "            os.system(f'{gdalcmd} {file_path} {tmp_out_path}')\n",
    "            # landmasking\n",
    "            os.system(f'gdal_calc.py -A {tmp_out_path} -B {tmp_landmask_file} --overwrite --outfile={out_path} \\\n",
    "                        --calc=\"(B==100)*A + (B!=100)*{no_data}\" --type={dtype} --co=\"ZLEVEL=9\" --co=\"COMPRESS=DEFLATE\" \\\n",
    "                        --co=\"BLOCKXSIZE=2048\" --NoDataValue={no_data} --co=\"BLOCKYSIZE=2048\" \\\n",
    "                        --co=\"NUM_THREADS=8\" --co=\"SPARSE_OK=TRUE\"')\n",
    "            os.remove(file_path)\n",
    "            return out_path,file_name\n",
    "\n",
    "        args = [(i,tile_name,gdalwarp_bbox_final,p_table,tmp_landmask_file) for i in file_list]\n",
    "        for arg in args:\n",
    "            out_file,rn_file=para_gdal_warp(arg[0],arg[1],arg[2],arg[3],arg[4])\n",
    "            s3_path = f\"{tile_name}/{rn_file}\"\n",
    "            client.fput_object(s3_config['bucket'], s3_path, out_file)\n",
    "            os.remove(out_file)\n",
    "            ttprint(f'{ip}://tmp-global-geomorpho/{s3_path} on S3')\n",
    "        os.remove(tmp_dtm_ls_file)\n",
    "        os.remove(tmp_dtm_rls_file)\n",
    "        os.system(f'rm -r {tmp_outdir}/*')\n",
    "        ttprint(f\"{tile_name} crop and save to local--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "Parallel(n_jobs=10)(delayed(worker)(i,p_table) for i in args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
